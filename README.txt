# Project Overview

This project consists of three main programs to build and query an inverted index for a collection of web documents:
1. `Tokenizer`: Tokenizes the documents and generates initial indices.
2. `Indexer`: Builds the inverted index from the tokenized documents.
3. `IndexReader`: Queries the inverted index to retrieve document and term information.

## Prerequisites

- Ensure you have Kotlin installed.
- The HTML parsing library `Jsoup` and a stemming library (e.g., `snowball`) must be included in your project dependencies.
- Make sure `stopwords.txt` is available in the working directory.

## Running the Programs

### Step 1: Tokenizing Documents

Run the `Tokenizer` program first to process the documents and generate the initial indices.

Usage:
java -jar Tokenizer.jar <directory>

Example:
java -jar Tokenizer.jar /path/to/documents

This will create the following files:
- `docids.txt`
- `termids.txt`
- `doc_index.txt`

### Step 2: Building the Inverted Index

Run the `Indexer` program to build the inverted index from the tokenized documents.

Usage:
java -jar Indexer.jar

This will create the following files:
- `term_index.txt`
- `term_info.txt`

### Step 3: Querying the Inverted Index

Run the `IndexReader` program to query the inverted index. This program accepts command-line arguments to retrieve information about documents and terms.

Usage:
java -jar IndexReader.jar [--doc DOCNAME | --term TERM | --term TERM --doc DOCNAME]

Examples:
1. Get document information:
java -jar IndexReader.jar --doc clueweb12-0000tw-13-04988

Output:
Listing for document: clueweb12-0000tw-13-04988
DOCID: 1
Distinct terms: 154
Total terms: 253

2. Get term information:
java -jar IndexReader.jar --term chocolate

Output:
Listing for term: chocolate
TERMID: 1
Number of documents containing term: 210
Term frequency in corpus: 8222
Inverted list offset: 0

3. Get term information in a specific document:
java -jar IndexReader.jar --term chocolate --doc clueweb12-0000tw-13-04988

Output:
Inverted list for term: chocolate
In document: clueweb12-0000tw-13-04988
TERMID: 1
DOCID: 1
Term frequency in document: 24
Positions: 1, 8, 13, 16, 25, 34, 51, 63, 91, 100, 119, 130, 151, 156, 160, 163, 168, 177, 188, 204, 208, 211, 222, 224

## Extra Credit

Didn't attempt to implement extra credit

## Notes

- Ensure all paths provided to the programs are absolute paths for consistent behavior.
- The `docids.txt`, `termids.txt`, and `doc_index.txt` files generated by the `Tokenizer` must be in the same directory as the `Indexer` and `IndexReader` programs.
- The `Indexer` should be run after the `Tokenizer` and before the `IndexReader`.